{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'context'],\n",
       "        num_rows: 202767\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'answer', 'context'],\n",
       "        num_rows: 2646\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "# Long-form question answering dataset, nicely preprocessed already.\n",
    "# Similar to ELI5: https://facebookresearch.github.io/ELI5/index.html (which is unavailable now)\n",
    "# I use my filtered version\n",
    "dataset_lfqa = datasets.load_dataset(\"stefanbschneider/lfqa-max-answer-length-512\")\n",
    "dataset_lfqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e00146937c42458e7dfa73ea4cd988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f46a06530884a97970a95c5ac1e12e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/648M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74bb50eade94443b9062264e7b3a6390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/231 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/led-base-16384\")\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/led-base-16384\")\n",
    "tuned_model = AutoModelForSeq2SeqLM.from_pretrained(\"stefanbschneider/led-base-16384-lfqa-ans-len-512\")\n",
    "tuned_model2 = AutoModelForSeq2SeqLM.from_pretrained(\"stefanbschneider/led-base-16384-lfqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"what's the difference between a forest and a wood?\",\n",
       " 'answer': \"They're used interchangeably a lot. You'll get different answers from different resources, but the general consensus seems to be that woods are smaller than forests.\\n\\n >  A wood is an area covered in trees, larger than a grove or a copse. A forest is also an area covered in trees, but it is larger than a wood\\n\\n >  The U.S. National Vegetation Classification system differentiates them according to their densities: 25 to 60 percent of a a wood is covered by tree canopies, while 60 to 100 percent of a forest is canopied.\",\n",
       " 'context': ['Wood is divided, according to its botanical origin, into two kinds: softwoods, from coniferous trees, and hardwoods, from broad-leaved trees. Softwoods are lighter and generally simple in structure, whereas hardwoods are harder and more complex. However, in Australia, \"softwood\" generally describes rain forest trees, and \"hardwood\" describes Sclerophyll species (\"Eucalyptus\" \"spp\").\\n',\n",
       "  'Woodland is defined by Chambers English dictionary as \"land covered with wood\" i.e. dominated by tree species. Forestry is defined as \"1. the science and art of planting, tending and managing forests; 2. Forest country\". This implies that forests have been planted by mankind for a variety of purposes, but mostly for exploitation for timber and pulp for the paper industry. The majority of Forests in Wales were planted by the British Forestry Commission, a UK government agency. Since 2016 the Forestry Commission in Wales has been taken over by Natural Resources Wales (NRW).\\n',\n",
       "  'A woodland or wood (or in the U.S., the \"plurale tantum\" woods) is a low-density forest forming open habitats with plenty of sunlight and limited shade. Woodlands may support an understory of shrubs and herbaceous plants including grasses. Woodland may form a transition to shrubland under drier conditions or during early stages of primary or secondary succession. Higher density areas of trees with a largely closed canopy that provides extensive and nearly continuous shade are referred to as forests. \\n',\n",
       "  'Timber means trunks and branches of trees, whether standing or not, and all wood. This definition includes the full range of wood products; all categories of saw logs, veneer logs, pulpwood and firewood.\\n',\n",
       "  'A forest product is any material derived from forestry for direct consumption or commercial use, such as lumber, paper, or forage for livestock. Wood, by far the dominant product of forests, is used for many purposes, such as wood fuel (e.g. in form of firewood or charcoal) or the finished structural materials used for the construction of buildings, or as a raw material, in the form of wood pulp, that is used in the production of paper. All other non-wood products derived from forest resources, comprising a broad variety of other forest products, are collectively described as non-timber forest products (NTFP). Non-timber forest products are viewed to have fewer negative effects on forest ecosystem when providing income sources for local community.\\n',\n",
       "  'Wood is a product of trees, and sometimes other fibrous plants, used for construction purposes when cut or pressed into lumber and timber, such as boards, planks and similar materials. It is a generic building material and is used in building just about any type of structure in most climates. Wood can be very flexible under loads, keeping strength while bending, and is incredibly strong when compressed vertically. There are many differing qualities to the different types of wood, even among same tree species. This means specific species are better suited for various uses than others. And growing conditions are important for deciding quality.\\n',\n",
       "  'Processing and products differs especially with regard to the distinction between softwood and hardwood. While softwood primarily goes into the production of wood fuel and pulp and paper, hardwood is used mainly for furniture, floors, etc.. Both types can be of use for building and (residential) construction purposes (e.g. log houses, log cabins, timber framing).\\n']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset_lfqa[\"train\"][0]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 727 to 1024 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'question: what\\'s the difference between a forest and a wood?, context: Wood is divided, according to its botanical origin, into two kinds: softwoods, from coniferous trees, and hardwoods, from broad-leaved trees. Softwoods are lighter and generally simple in structure, whereas hardwoods are harder and more complex. However, in Australia, \"softwood\" generally describes rain forest trees, and \"hardwood\" describes Sclerophyll species (\"Eucalyptus\" \"spp\"). Woodland is defined by Chambers English dictionary as \"land covered with wood\" i.e. dominated by tree species. Forestry is defined as \"1. the science and art of planting, tending and managing forests; 2. Forest country\". This implies that forests have been planted by mankind for a variety of purposes, but mostly for exploitation for timber and pulp for the paper industry. The majority of Forests in Wales were planted by the British Forestry Commission, a UK government agency. Since 2016 the Forestry Commission in Wales has been taken over by Natural Resources Wales (NRW). Woodland is a type of forest that is dominated by tree species. Woodland is a type of forest that is dominated by tree species. Woodland is a type of forest that is dominated by tree species. Woodland is a type of forest that is dominated by tree species. The majority of Forests in Wales were planted by the British Forestry Commission, a UK government agency. Since 2016 the Forestry Commission in Wales has been taken over by Natural Resources Wales (NRW). Woodland is a type of forest that is dominated by tree species. A woodland or wood (or in the U.S., the \"plurale tantum\" woods) is a low-density forest forming open habitats with plenty of sunlight and limited shade. Woodlands may support an understory of shrubs and herbaceous plants including grasses. Woodland may form a transition to shrubland under drier conditions or during early stages of primary or secondary succession. Higher density areas of trees with a largely closed canopy that provides extensive and nearly continuous shade are referred to as forests. Ã‚Woodland is a type of forest. Timber means trunks and branches of trees, whether standing or not, and all wood. This definition includes the full range of wood products; all categories of saw logs, veneer logs, pulpwood and firewood. Woodland is a type of wood that is used for many purposes. A forest product is any material derived'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = f\"question: {example['question']}, context: {' '.join(example['context'])}\"    \n",
    "tokens = tokenizer(input, return_tensors=\"pt\")\n",
    "\n",
    "# base model\n",
    "base_model_output = base_model.generate(**tokens, max_length=512)\n",
    "base_model_answer = tokenizer.decode(base_model_output[0], skip_special_tokens=True)\n",
    "base_model_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.18969072164948456,\n",
       " 'rouge2': 0.033126293995859216,\n",
       " 'rougeL': 0.11958762886597939,\n",
       " 'rougeLsum': 0.15257731958762888}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge.compute(predictions=[base_model_answer], references=[example['answer']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A forest is an area of land covered with trees. A wood is a piece of land that is covered by trees.\\n\\nA tree is a part of a forest.\\n\\n_URL_0_\\n\\nThe difference between a forest and a wood is that a forest is more dense than a tree, and a tree is more complex than a wood. \\n\\nSo, a forest means that a tree grows in a way that allows it to grow in a more dense area. \\nA wood means that it grows in an area where it can grow in more dense areas.  A forest is a place where a tree can grow and grow in less dense areas than a forest can grow. \\n\\n\\nA forest means a place that grows in such dense areas that it can be used for a variety of purposes.  For example, a tree that grows on a tree will grow in such a way to support a tree.  The tree will be able to support the tree, but the tree will not be strong enough to support it.  \\n\\n\\n\\n\\n\\n\"A forest\" means a forest where a forest grows in the same way as a tree growing in a different area.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n > \\n\\n >\\n\\n\\n >\\n\\n >\\n\\n >\\n\\n >\\n >\\n \\n\\n\\n\\n \\n \\n\\n \\n\\n\\n\\n >     \\n \\n > > \\n\"The forest\" is a word that means \"land covered in trees.\"\\n\\nIf you mean \"wood\" or \"woodland.\"\\n\"woodland\" means \"wood.\" >  \"woodlands\" means trees that grow in different areas of the world.  If you want to know more about trees, you\\'d have to know a lot about trees.\\n If you want a tree to be a forest, then you\\'d need to know that trees grow in trees.  You\\'d need trees to be trees, and trees are a tree species.\\n\\n\\n & #x200B;\\n\\n*\\n*\\n\\n\\n*\\n\\n**\\n\\n\\n\\n*\\n\\n > (_URL_1_)\\n\\nHope that helps_(_URL_2_)h\"|u | &\\r'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same for fine-tuned model\n",
    "tuned_model_output = tuned_model.generate(**tokens, max_length=512)\n",
    "tuned_model_answer = tokenizer.decode(tuned_model_output[0], skip_special_tokens=True)\n",
    "tuned_model_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.2864583333333333,\n",
       " 'rouge2': 0.12041884816753927,\n",
       " 'rougeL': 0.14583333333333334,\n",
       " 'rougeLsum': 0.26562499999999994}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge.compute(predictions=[tuned_model_answer], references=[example['answer']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "base_pipeline = pipeline(task=\"text2text-generation\", model=\"allenai/led-base-16384\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'question: What is the capital of Germany?, context: Germany is a country in Europe. Its'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_pipeline(\"question: What is the capital of Germany?, context: Germany is a country in Europe. Its capital is Berlin.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "lfqa_pipeline = pipeline(task=\"text2text-generation\", model=\"stefanbschneider/led-base-16384-lfqa-ans-len-512\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The capital of Germany is Berlin.\\n\\nThe capital is Berlin, which is the capital of the German state of Brandenburg.\\n\\n_URL_0_\\n\\nGermany is the largest city in Europe, with a population of around 10 million.\\n \\n\\nIt\\'s the capital, Berlin. \\n\\n_\\n_\\n\\n\\n\\n\"Berlin\" is the name of the city in Germany. \"Berliner\" is a German name for the city of Berlin.\\n\\n\\n\\n\\n\" Berlin\" is an abbreviation of \"Berlin\", which means \"German capital\".\\n\\n\\n\\n\\n\\nThe name of Berlin is \"Berliner\", which is a name for Berlin.\\n\\n\\n\\nThe title of the \"German Capital of Germany\" is German for \"Germany\" and \"German City of Berlin\".\\n\\nBerlin is a city in the German capital of Berlin, Berlin is a country in Europe. \\n\\n\\nGermany has a capital called Berlin, and a city called Berlin is Germany\\'s capital.  \\n\\n\\n\\n\\n\\n_\\n \\n \\n\\n\\n\\n\\n\\n\\n >\\n\\n\\n >\\n\\n\\n_\\n\\n\\n >\\n >\\n\\n\\n >\\r\\n\\n \\n\\n > \\n > \\n\\n >\\n\\n\\n\\n \\n  \\n_ >\\n > >\\n_\\r\\n >_\\n >;\\n\\n-\\n\\n--\\n\\n\\n--\\n\\n*\\n\\n\\\\-\\n\\n---\\n\\nHope this is a good place to start.\\n\\n\\n-\\n\\n\\n**\\n\\r >\\n_\\n\\n \\n\\n_\\n >\\n\\n \\n\\n_URL\\n\\n\\n\\n\\n\\n\\r\\n\\n\\nHope that helps.\\n\\n >     >\\n\\n\\r\\n\"Germany\"|(_URL_\\n);^h~~**\\n\\n*\\n\\n\\n|\\n|\\n\\n||\\n\\n|||\\n\\n\\n\\n|\\n||\\n|\\n\\n\\n\\n\\n|\\n\\n||\\n\\n\\n _URL|~~~~~~||~~~~\\n\\n~~~~**||---||**|~~|\\n\\n~~\\n\\n\\n\\n~~~~~~\\n~~|~~\\n\\n|~~|\\n\\n~~\\n\\n** ;))\\n\\n] )'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfqa_pipeline(\"question: What is the capital of Germany?, context: Germany is a country in Europe. Its capital is Berlin.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: what's the difference between a forest and a wood?, context: Wood is divided, according to its botanical origin, into two kinds: softwoods, from coniferous trees, and hardwoods, from broad-leaved trees. Softwoods are lighter and generally simple in structure, whereas hardwoods are harder and more complex. However, in Australia, \"softwood\" generally describes rain forest trees, and \"hardwood\" describes Sclerophyll species (\"Eucalyptus\" \"spp\").\n",
      " Woodland is defined by Chambers English dictionary as \"land covered with wood\" i.e. dominated by tree species. Forestry is defined as \"1. the science and art of planting, tending and managing forests; 2. Forest country\". This implies that forests have been planted by mankind for a variety of purposes, but mostly for exploitation for timber and pulp for the paper industry. The majority of Forests in Wales were planted by the British Forestry Commission, a UK government agency. Since 2016 the Forestry Commission in Wales has been taken over by Natural Resources Wales (NRW).\n",
      " A woodland or wood (or in the U.S., the \"plurale tantum\" woods) is a low-density forest forming open habitats with plenty of sunlight and limited shade. Woodlands may support an understory of shrubs and herbaceous plants including grasses. Woodland may form a transition to shrubland under drier conditions or during early stages of primary or secondary succession. Higher density areas of trees with a largely closed canopy that provides extensive and nearly continuous shade are referred to as forests. \n",
      " Timber means trunks and branches of trees, whether standing or not, and all wood. This definition includes the full range of wood products; all categories of saw logs, veneer logs, pulpwood and firewood.\n",
      " A forest product is any material derived from forestry for direct consumption or commercial use, such as lumber, paper, or forage for livestock. Wood, by far the dominant product of forests, is used for many purposes, such as wood fuel (e.g. in form of firewood or charcoal) or the finished structural materials used for the construction of buildings, or as a raw material, in the form of wood pulp, that is used in the production of paper. All other non-wood products derived from forest resources, comprising a broad variety of other forest products, are collectively described as non-timber forest products (NTFP). Non-timber forest products are viewed to have fewer negative effects on forest ecosystem when providing income sources for local community.\n",
      " Wood is a product of trees, and sometimes other fibrous plants, used for construction purposes when cut or pressed into lumber and timber, such as boards, planks and similar materials. It is a generic building material and is used in building just about any type of structure in most climates. Wood can be very flexible under loads, keeping strength while bending, and is incredibly strong when compressed vertically. There are many differing qualities to the different types of wood, even among same tree species. This means specific species are better suited for various uses than others. And growing conditions are important for deciding quality.\n",
      " Processing and products differs especially with regard to the distinction between softwood and hardwood. While softwood primarily goes into the production of wood fuel and pulp and paper, hardwood is used mainly for furniture, floors, etc.. Both types can be of use for building and (residential) construction purposes (e.g. log houses, log cabins, timber framing).\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'A forest is an area of land covered with trees. A wood is a piece of land that is covered by trees.\\n\\nA tree is a part of a forest.\\n\\n_URL_0_\\n\\nThe difference between a forest and a wood is that a forest is more dense than a tree, and a tree is more complex than a wood. \\n\\nSo, a forest means that a tree grows in a way that allows it to grow in a more dense area. \\nA wood means that it grows in an area where it can grow in more dense areas.  A forest is a place where a tree can grow and grow in less dense areas than a forest can grow. \\n\\n\\nA forest means a place that grows in such dense areas that it can be used for a variety of purposes.  For example, a tree that grows on a tree will grow in such a way to support a tree.  The tree will be able to support the tree, but the tree will not be strong enough to support it.  \\n\\n\\n\\n\\n\\n\"A forest\" means a forest where a forest grows in the same way as a tree growing in a different area.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n > \\n\\n >\\n\\n\\n >\\n\\n >\\n\\n >\\n\\n >\\n >\\n \\n\\n\\n\\n \\n \\n\\n \\n\\n\\n\\n >     \\n \\n > > \\n\"The forest\" is a word that means \"land covered in trees.\"\\n\\nIf you mean \"wood\" or \"woodland.\"\\n\"woodland\" means \"wood.\" >  \"woodlands\" means trees that grow in different areas of the world.  If you want to know more about trees, you\\'d have to know a lot about trees.\\n If you want a tree to be a forest, then you\\'d need to know that trees grow in trees.  You\\'d need trees to be trees, and trees are a tree species.\\n\\n\\n & #x200B;\\n\\n*\\n*\\n\\n\\n*\\n\\n**\\n\\n\\n\\n*\\n\\n > (_URL_1_)\\n\\nHope that helps_(_URL_2_)h\"|u | &\\r'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(input)\n",
    "lfqa_pipeline(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38edf328b2b74b398152569b566ef5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.43k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef8c34ca3bf4fea99f7d26691662fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c17b8e11e474c01a78840fa26c7c7f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65bd4f150ce149ed8a27359a85049ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.56M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec805de96c3a429cad2fe40393c50c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/957 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "lfqa_pipeline2 = pipeline(task=\"text2text-generation\", model=\"stefanbschneider/led-base-16384-lfqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The capital of Germany is Berlin, which is the capital of the German state of Brandenburg.\\n\\nThe capital is Berlin.\\n\\n_URL_0_\\n\\n\\n \\n\\nGermany is the largest city in Europe, with a population of around 1.5 million.   \\n  \\n\\n\\nGermany has a population density of about 1.2 million people.  Germany is the second largest city, with an average density of 1.4 million people per square kilometer.\\n \\nGermany\\'s population density is about 2.3 million people/square kilometers.  So, Germany has a total density of around 2.2 billion people/ square kilometers.\\n   \\n > \\n \\n\\n >  Germany\\'s capital was Berlin.  The capital of Berlin was Berlin, but it was not the largest.  It was the capital for Germany. \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGermany:\\n\\n* Germany: \\n* Berlin.\\n*Germany: \\n\\n\\n\\n > Germany:\\n\\n > Berlin, Germany, Germany\\n* France, France\\n* Italy\\n* Spain\\n* Japan\\n* Russia\\n* China\\n* Korea\\n* India\\n* Vietnam\\n* Pakistan\\n* South Africa\\n* Egypt\\n* Iran\\n* Sudan\\n* Syria\\n* Iraq\\n* Afghanistan\\n* Libya\\n* Yemen\\n* Saudi Arabia\\n*Iran\\n* Arabia\\n\\n**Iran**\\n*Iraq\\n* Kuwait\\n* Lebanon\\n* Qatar\\n* Turkey\\n* Jordan\\n* Palestine\\n* Israel\\n\\nAll of these are the capitals of Germany.\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n \\n > Germany\\n\\nIf you want to know more about Germany, I\\'d be happy to answer any follow-up questions you might have.\\n\\n & \\n\\n\\n*\\n\\n* Germany*, Germany*, France, Japan, China, India, Iran, Pakistan, Iran\\n\\n^\\n**Germany**\\n\\n\\n\\n\\n\\n** Germany**\\n**Russia**\\n Germany** Russia**\\n\\n\\n\\n  Germany **Germany**\\n\\n\\n* Austria**\\n\\n** Austria**\\n\\n\\n\\n\\n ** Germany**\\n\\n ** Austria**\\n\\n  >   Germany**\\r\\n\\n\\r\\n_ Berlin ;) :) :-)... . ...?\" )'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfqa_pipeline2(\"question: What is the capital of Germany?, context: Germany is a country in Europe. Its capital is Berlin.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'A forest is a low density area of trees. A wood is high density areas of trees with lots of shade. A forest is low density areas that provide extensive and nearly continuous shade, whether standing or not, and generally have plenty of sunlight and limited shade.\\n\\nA wood is a high density area where trees have a lot of shade and trees have little shade.\\n\\n_URL_0_\\n \\n\\nThe difference between a forest and a wood is that a forest is lower density, but a wood has a lot more shade and can support more trees than a forest.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe distinction between a wood and a forest depends on what you mean by \"wood\" and \"wood\". Wood is a type of wood. Wood is the type of tree that can support trees. Woodland is the kind of wood that can be supported by trees, but not supported by a tree. Woodlands are the type that can\\'t support a tree, but can support the tree. \\n\\n\\n\\n \\n\\n\\nA forest can be considered a forest if it has a high level of shade, or if it is a wood. \\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n\\n \\n\\n \\n  \\n     > \\n > \\n\\n >   & \\n\\n\\n \\n\\n &   < \\n\"Wood\"\\n\\n\"wood\" means \"wood.\"\\n\\nand \"woodland\" means a type that supports trees.\\n\\n\\n\" wood\" means trees that support trees that are supported by other types of trees, such as wood.\\n\\n\"woodwood\" is the same as \"wood\", or \"woodwood\".\\n\\n\\n\\n > \"wood tree\" is a different from \"wood trees\".\\n\\n\\nand so on and so on.\\n\\n\\n\\n \"wood is different from wood trees, and wood trees are different than wood trees.\"\\n\\n\\n\\n >\\n\\n\\n >\\n\\n >\\n\\n\\n >\\n\" Wood\" is just a term used to refer to trees that have a higher density, or have more shade.\\n\\n >\\n\" Wood\"\"\\n\" \"\". \"  .??\"(\\n... ..._\"\"......'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfqa_pipeline2(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<s>',\n",
       " 'eos_token': '</s>',\n",
       " 'unk_token': '<unk>',\n",
       " 'sep_token': '</s>',\n",
       " 'pad_token': '<pad>',\n",
       " 'cls_token': '<s>',\n",
       " 'mask_token': '<mask>'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer2 = AutoTokenizer.from_pretrained(\"stefanbschneider/led-base-16384-lfqa\")\n",
    "tokenizer2.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "### --- use evaluator to compute rouge score on entire validation set --- ###\n",
    "from transformers import pipeline\n",
    "\n",
    "val_data = datasets.load_dataset(\"stefanbschneider/lfqa-max-answer-length-512\", split=\"validation\").shuffle().select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'context'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data = dataset_lfqa[\"validation\"].shuffle().select(range(3))\n",
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7d66ae63444e1885ac62719341a780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'context', 'question_context'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concat_question_and_context(batch):\n",
    "    # combine context strings and questions to one input\n",
    "    batch[\"question_context\"] = [\n",
    "        f\"question: {question}, context: {' '.join(context)}\"\n",
    "        for question, context in zip(batch[\"question\"], batch[\"context\"])\n",
    "    ]\n",
    "    return batch\n",
    "\n",
    "\n",
    "val_data = val_data.map(concat_question_and_context, batched=True, batch_size=2)\n",
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'during 9/11, why didnt firefighters/rescue teams set up safety nets for people stuck at the top of the burning buildings to jump out onto and land on?',\n",
       " 'answer': 'Jumping off a buildings with 110 floors, reaching terminal velocity, into a net just above the ground?\\n\\n_URL_0_',\n",
       " 'context': ['The area around the building was cleared of pedestrians and firefighting personnel because of falling glass and debris. The falling debris was dangerous for firefighters because they often had to cross the perimeter around the building to enter and leave the high-rise. Hose lines stretched into the building were damaged by falling debris and one firefighter was struck by debris and seriously injured while tending to the lines.\\n',\n",
       "  \"The first service to attend were a Patient Transport Ambulance crew who took the decision to divert straight to the scene because they were so close at the time of the explosion. This initial crew saved dozens of lives by taking control of the evacuation and pulling the injured to safety. Around a dozen were trapped in the rubble. Fire crews used specialist search-and-rescue equipment, including sniffer dogs, carbon dioxide detectors (which detect the respired carbon dioxide of trapped persons), thermal-imaging equipment, and fibre-optic cameras to search for people trapped in the collapsed building. Some trapped workers were able to make themselves heard by shouting, or by using their mobile phones. Fire and Ambulance crews pulled seven people alive from the rubble on 11 May. The search through the factory's ruins continued for the following three days.\\n\",\n",
       "  'Protection of human life is first priority for firefighters. Since 1995, when arriving on a scene, a fire crew will establish safety zones and escape routes, verify communication is in place, and designate lookouts (known in the U.S. by the acronym \"LCES\", for lookouts, communications, escape routes, safety zones). This allows the firefighters to engage a fire with options for a retreat should their current situation become unsafe. Although other safety zones should be designated, areas already burned generally provide a safe refuge from fire provided they have cooled sufficiently, are accessible, and have burned enough fuels so as to not reignite. Briefings may be done to inform new fire resources of hazards and other pertinent information.\\n',\n",
       "  'Knowing where the emergency exits are in buildings can save lives. Some buildings, such as schools, have fire drills to practice using emergency exits. Many disasters could have been prevented if people had known where fire escapes were and if emergency exits had not been blocked. For example, in the September 11, 2001, attacks on the World Trade Center, some of the emergency exits inside the building were inaccessible, while others were locked. In the Stardust Disaster and the 2006 Moscow hospital fire, the emergency exits were locked and most windows barred shut. In the case of the Station Nightclub, the premises was over capacity the night fire broke out, the front exit was not designed well (right outside the door, the concrete approach split 90 degrees and a railing ran along the edge), and an emergency exit swung inward, not outward as code requires.\\n',\n",
       "  \"As the interior crews started their interior attack of the fire, four firefighters made their way to the roof to begin ventilation operations. While the ladder crews were venting the roof, it collapsed below them. One firefighter landed next to the main entrance after falling through the roof. Another firefighter held onto a wall and was pulled up by the other two firefighters that were on the only part of the roof that didn't collapse.\\n\",\n",
       "  'Television coverage of the event showed people holding on to scaffolding around the building, and some were able to climb down to safety. One worker on the 28th floor said that workers were adding insulation to the building when the fire broke out.\\n',\n",
       "  'Emergency responders arriving to treat the jumpers learned of the building fire and evacuation efforts commenced. Firefighters removed the bodies of 44 people (32 men and 12 women) from inside the building, and rescued those who managed to flee to the roof.\\n'],\n",
       " 'question_context': 'question: during 9/11, why didnt firefighters/rescue teams set up safety nets for people stuck at the top of the burning buildings to jump out onto and land on?, context: The area around the building was cleared of pedestrians and firefighting personnel because of falling glass and debris. The falling debris was dangerous for firefighters because they often had to cross the perimeter around the building to enter and leave the high-rise. Hose lines stretched into the building were damaged by falling debris and one firefighter was struck by debris and seriously injured while tending to the lines.\\n The first service to attend were a Patient Transport Ambulance crew who took the decision to divert straight to the scene because they were so close at the time of the explosion. This initial crew saved dozens of lives by taking control of the evacuation and pulling the injured to safety. Around a dozen were trapped in the rubble. Fire crews used specialist search-and-rescue equipment, including sniffer dogs, carbon dioxide detectors (which detect the respired carbon dioxide of trapped persons), thermal-imaging equipment, and fibre-optic cameras to search for people trapped in the collapsed building. Some trapped workers were able to make themselves heard by shouting, or by using their mobile phones. Fire and Ambulance crews pulled seven people alive from the rubble on 11 May. The search through the factory\\'s ruins continued for the following three days.\\n Protection of human life is first priority for firefighters. Since 1995, when arriving on a scene, a fire crew will establish safety zones and escape routes, verify communication is in place, and designate lookouts (known in the U.S. by the acronym \"LCES\", for lookouts, communications, escape routes, safety zones). This allows the firefighters to engage a fire with options for a retreat should their current situation become unsafe. Although other safety zones should be designated, areas already burned generally provide a safe refuge from fire provided they have cooled sufficiently, are accessible, and have burned enough fuels so as to not reignite. Briefings may be done to inform new fire resources of hazards and other pertinent information.\\n Knowing where the emergency exits are in buildings can save lives. Some buildings, such as schools, have fire drills to practice using emergency exits. Many disasters could have been prevented if people had known where fire escapes were and if emergency exits had not been blocked. For example, in the September 11, 2001, attacks on the World Trade Center, some of the emergency exits inside the building were inaccessible, while others were locked. In the Stardust Disaster and the 2006 Moscow hospital fire, the emergency exits were locked and most windows barred shut. In the case of the Station Nightclub, the premises was over capacity the night fire broke out, the front exit was not designed well (right outside the door, the concrete approach split 90 degrees and a railing ran along the edge), and an emergency exit swung inward, not outward as code requires.\\n As the interior crews started their interior attack of the fire, four firefighters made their way to the roof to begin ventilation operations. While the ladder crews were venting the roof, it collapsed below them. One firefighter landed next to the main entrance after falling through the roof. Another firefighter held onto a wall and was pulled up by the other two firefighters that were on the only part of the roof that didn\\'t collapse.\\n Television coverage of the event showed people holding on to scaffolding around the building, and some were able to climb down to safety. One worker on the 28th floor said that workers were adding insulation to the building when the fire broke out.\\n Emergency responders arriving to treat the jumpers learned of the building fire and evacuation efforts commenced. Firefighters removed the bodies of 44 people (32 men and 12 women) from inside the building, and rescued those who managed to flee to the roof.\\n'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n",
      "Input ids are automatically padded from 780 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 864 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 940 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 999 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 768 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 939 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 993 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 657 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 815 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 682 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 790 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1544 to 2048 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 706 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 774 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 957 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 737 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 796 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 696 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 811 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 739 to 1024 to be a multiple of `config.attention_window`: 1024\n",
      "Input ids are automatically padded from 1209 to 2048 to be a multiple of `config.attention_window`: 1024\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m task_evaluator \u001b[38;5;241m=\u001b[39m evaluator(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext2text-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m pipe \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext2text-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstefanbschneider/led-base-16384-lfqa-ans-len-512\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtask_evaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_or_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion_context\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manswer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m results\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/llm/lib/python3.12/site-packages/evaluate/evaluator/text2text_generation.py:133\u001b[0m, in \u001b[0;36mText2TextGenerationEvaluator.compute\u001b[0;34m(self, model_or_pipeline, data, subset, split, metric, tokenizer, strategy, confidence_level, n_resamples, device, random_state, input_column, label_column, generation_kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPIPELINE_KWARGS\u001b[38;5;241m.\u001b[39mupdate(generation_kwargs)\n\u001b[0;32m--> 133\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_or_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_or_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfidence_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfidence_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_resamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_resamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/llm/lib/python3.12/site-packages/evaluate/evaluator/base.py:255\u001b[0m, in \u001b[0;36mEvaluator.compute\u001b[0;34m(self, model_or_pipeline, data, subset, split, metric, tokenizer, feature_extractor, strategy, confidence_level, n_resamples, device, random_state, input_column, label_column, label_mapping)\u001b[0m\n\u001b[1;32m    252\u001b[0m metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_metric(metric)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# Compute predictions\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m predictions, perf_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipe_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictions_processor(predictions, label_mapping)\n\u001b[1;32m    258\u001b[0m metric_inputs\u001b[38;5;241m.\u001b[39mupdate(predictions)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/llm/lib/python3.12/site-packages/evaluate/evaluator/base.py:513\u001b[0m, in \u001b[0;36mEvaluator.call_pipeline\u001b[0;34m(self, pipe, *args, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_pipeline\u001b[39m(\u001b[38;5;28mself\u001b[39m, pipe, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    512\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[0;32m--> 513\u001b[0m     pipe_output \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPELINE_KWARGS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pipe_output, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_time_perf(start_time, end_time, \u001b[38;5;28mlen\u001b[39m(pipe_output))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/llm/lib/python3.12/site-packages/transformers/pipelines/text2text_generation.py:173\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    145\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(el, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[1;32m    178\u001b[0m     ):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/llm/lib/python3.12/site-packages/transformers/pipelines/base.py:1343\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[1;32m   1340\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   1341\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1342\u001b[0m     )\n\u001b[0;32m-> 1343\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/llm/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/llm/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:125\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m    124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[0;32m--> 125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/llm/lib/python3.12/site-packages/transformers/pipelines/base.py:1269\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1268\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1269\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1270\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/llm/lib/python3.12/site-packages/transformers/pipelines/text2text_generation.py:202\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[1;32m    200\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[0;32m--> 202\u001b[0m output_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m out_b \u001b[38;5;241m=\u001b[39m output_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/llm/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/llm/lib/python3.12/site-packages/transformers/generation/utils.py:2286\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2278\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2279\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2280\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2281\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2282\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2283\u001b[0m     )\n\u001b[1;32m   2285\u001b[0m     \u001b[38;5;66;03m# 13. run beam sample\u001b[39;00m\n\u001b[0;32m-> 2286\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2287\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2292\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2293\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2294\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[1;32m   2297\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2298\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2299\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2300\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2306\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2307\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/llm/lib/python3.12/site-packages/transformers/generation/utils.py:3589\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3586\u001b[0m beam_next_tokens \u001b[38;5;241m=\u001b[39m beam_outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_beam_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   3587\u001b[0m beam_idx \u001b[38;5;241m=\u001b[39m beam_outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_beam_indices\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m-> 3589\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_next_tokens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3591\u001b[0m \u001b[38;5;66;03m# This is needed to properly delete outputs.logits which may be very large for first iteration\u001b[39;00m\n\u001b[1;32m   3592\u001b[0m \u001b[38;5;66;03m# Otherwise a reference to outputs is kept which keeps the logits alive in the next iteration\u001b[39;00m\n\u001b[1;32m   3593\u001b[0m \u001b[38;5;66;03m# IMPORTANT: Note that this should appear BEFORE the call to _reorder_cache() to save the maximum memory\u001b[39;00m\n\u001b[1;32m   3594\u001b[0m \u001b[38;5;66;03m# (that way the memory peak does not include outputs.logits)\u001b[39;00m\n\u001b[1;32m   3595\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m outputs\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from evaluate import evaluator\n",
    "\n",
    "task_evaluator = evaluator(\"text2text-generation\")\n",
    "pipe = pipeline(\"text2text-generation\", model=\"stefanbschneider/led-base-16384-lfqa-ans-len-512\", device=\"mps\")\n",
    "results = task_evaluator.compute(model_or_pipeline=pipe, data=val_data, metric=rouge, input_column=\"question_context\", label_column=\"answer\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
